{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b799b52",
   "metadata": {},
   "source": [
    "# Expanding the System - LogisticRegression, NaiveBayes and LinearSVC\n",
    "\n",
    "This notebook provides code for an extension of the basic system, covering more features represented as one-hot represenation. In this notebook I am also training three different models: LogisticRegression, NaiveBayes and LinearSVC (SVM). \n",
    "This time, I am adding to the baseline features  - `Token`, `POS`, `Cap_after_lower`, and `Allcaps` - and including several new features. `Chunk` takes the additional syntactical information given in the original CONLL format which represent dependencies, and `Demonym`, `Comp_suf`, and `Poss_mark` represent orthographic information based on the original data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import feature_extraction_util as extract\n",
    "import classification_util as classify\n",
    "import evaluation_util as evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58221661",
   "metadata": {},
   "source": [
    "#### The cell below contains necessary definitions in order to train the model, as well as classify the test-sets with pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Token', 'POS', 'Chunk', 'Allcaps', 'Cap_after_lower', 'Demonym', 'Comp_suf', 'Poss_mark']\n",
    "\n",
    "train_file = '../data/conll2003.train.preprocessed.conll'\n",
    "test_file = '../data/conll2003.test.preprocessed.conll'\n",
    "outputfile = '../data/conll2003.test.output.conll' # generic pathname for saving results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0bb14",
   "metadata": {},
   "source": [
    "## Extracting the features, training and saving the models\n",
    "\n",
    "If this cell has already been executed, the trained model is loaded in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf09a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features and labels\n",
    "training_features, gold_labels = extract.features_and_labels(train_file,selected_features)\n",
    "\n",
    "for modelname in ['logreg', 'NB', 'SVM']:\n",
    "    \n",
    "    # create classifier\n",
    "    model, vec = classify.create_classifier(training_features,gold_labels,modelname)\n",
    "    \n",
    "    # save trained model and vectorizer\n",
    "    classifier_pathname = '../models/expanded_%s_model_conll2003.sav' % modelname    \n",
    "    vectorizer_pathname = '../models/expanded_%s_vec_conll2003.sav' % modelname\n",
    "\n",
    "    pickle.dump(model, open(classifier_pathname, 'wb'))\n",
    "    pickle.dump(vec, open(vectorizer_pathname,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147ab55",
   "metadata": {},
   "source": [
    "## Classifying the test sets with the saved models and evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60934fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelname in ['logreg', 'NB', 'SVM']:\n",
    "    \n",
    "    # load saved model and vec\n",
    "    classifier_pathname = '../models/expanded_%s_model_conll2003.sav' % modelname\n",
    "    vectorizer_pathname = '../models/expanded_%s_vec_conll2003.sav' % modelname\n",
    "    \n",
    "    loaded_model = pickle.load(open(classifier_pathname,'rb'))\n",
    "    loaded_vec = pickle.load(open(vectorizer_pathname,'rb'))\n",
    "        \n",
    "    # classify data and write to file\n",
    "    classify.classify_data(loaded_model,loaded_vec,selected_features,test_file,\n",
    "                           outputfile.replace('.conll','.' + modelname + '.conll'))\n",
    "        \n",
    "    outputdata = '../data/conll2003.test.output.%s.conll' % modelname\n",
    "    \n",
    "    print(\"Classification Report and Confusion Matrix for the %s model\" % modelname)\n",
    "    evaluate.get_confusion_matrix_and_classification_report(outputdata,exclude_majority=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
